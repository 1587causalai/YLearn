{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four cases\n",
    "- Single treatment, single outcomes\n",
    "- Single treatment, multiple outcomes\n",
    "- Multiple treatments, single outcome\n",
    "- Multiple treatments, multiple outcomes\n",
    "\n",
    "For outcomes, we may also consider the combinations of continuous and discrete outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper imports \n",
    "import numpy as np\n",
    "from numpy.random import binomial, multivariate_normal, normal, uniform\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from estimator_model.meta_learner import SLearner, TLearner, XLearner\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DGP\n",
    "def generate_data(n, d, controls_outcome, treatment_effect, propensity):\n",
    "    \"\"\"Generates population data for given untreated_outcome, treatment_effect and propensity functions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        n (int): population size\n",
    "        d (int): number of covariates\n",
    "        controls_outcome (func): untreated outcome conditional on covariates\n",
    "        treatment_effect (func): treatment effect conditional on covariates\n",
    "        propensity (func): probability of treatment conditional on covariates\n",
    "    \"\"\"\n",
    "    # Generate covariates\n",
    "    X = multivariate_normal(np.zeros(d), np.diag(np.ones(d)), n)\n",
    "    # Generate treatment\n",
    "    T = np.apply_along_axis(lambda x: binomial(1, propensity(x), 1)[0], 1, X)\n",
    "    # Calculate outcome\n",
    "    Y0 = np.apply_along_axis(lambda x: controls_outcome(x), 1, X)\n",
    "    treat_effect = np.apply_along_axis(lambda x: treatment_effect(x), 1, X)\n",
    "    Y = Y0 + treat_effect * T\n",
    "    return (Y, T, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_controls_outcome(d):\n",
    "    beta = uniform(-3, 3, d)\n",
    "    return lambda x: np.dot(x, beta) + normal(0, 1)\n",
    "treatment_effect = lambda x: (1 if x[1] > 0.1 else 0)*8\n",
    "propensity = lambda x: (0.8 if (x[2]>-0.5 and x[2]<0.5) else 0.2)\n",
    "# DGP constants and test data\n",
    "d = 5\n",
    "n = 1000\n",
    "n_test = 250\n",
    "controls_outcome = generate_controls_outcome(d)\n",
    "X_test = multivariate_normal(np.zeros(d), np.diag(np.ones(d)), n_test)\n",
    "delta = 6/n_test\n",
    "X_test[:, 1] = np.arange(-3, 3, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x, w = generate_data(n, d, controls_outcome, treatment_effect, propensity)\n",
    "data_dict = {\n",
    "    'outcome': y,\n",
    "    'treatment': x,\n",
    "}\n",
    "test_dict = {}\n",
    "adjustment = []\n",
    "for i in range(w.shape[1]):\n",
    "    data_dict[f'w_{i}'] = w[:, i].squeeze()\n",
    "    test_dict[f'w_{i}'] = X_test[:, i].squeeze()\n",
    "    adjustment.append(f'w_{i}')\n",
    "outcome = 'outcome'\n",
    "treatment = 'treatment'\n",
    "data = pd.DataFrame(data_dict)\n",
    "test_data = pd.DataFrame(test_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = SLearner(model=GradientBoostingRegressor())\n",
    "s.fit(\n",
    "    data=data,\n",
    "    outcome=outcome,\n",
    "    treatment=treatment,\n",
    "    adjustment=adjustment,\n",
    ")\n",
    "s_pred = s.estimate(data=test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TLearner(\n",
    "    model=GradientBoostingRegressor()\n",
    ")\n",
    "t.fit(\n",
    "    data=data,\n",
    "    outcome=outcome,\n",
    "    treatment=treatment,\n",
    "    adjustment=adjustment,\n",
    ")\n",
    "t_pred = t.estimate(data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = XLearner(\n",
    "    model=\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e0ecfad75f99b8578830c76494b15e8b8f0ed30d484e3d7b0b2aac43eb800e14"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('causal')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
